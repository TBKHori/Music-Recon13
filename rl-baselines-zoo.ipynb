{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJy9QoDC7XA7"
      },
      "source": [
        "# RL Baselines3 Zoo: Training in Colab\n",
        "\n",
        "\n",
        "\n",
        "Github Repo: [https://github.com/DLR-RM/rl-baselines3-zoo](https://github.com/DLR-RM/rl-baselines3-zoo)\n",
        "\n",
        "Stable-Baselines3 Repo: [https://github.com/DLR-RM/rl-baselines3-zoo](https://github.com/DLR-RM/stable-baselines3)\n",
        "\n",
        "\n",
        "# Install Dependencies\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "dcc-TSL149q8"
      },
      "outputs": [],
      "source": [
        "# for autoformatting\n",
        "# %load_ext jupyter_black"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXVDDlTn02M9",
        "outputId": "2df6830f-b195-4884-dd7e-4a2b710a8c00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.ubuntu.com (91.189.91\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connecting to security.ubuntu.com (91.189.91\r                                                                                                    \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:6 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,194 kB]\n",
            "Hit:7 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [109 kB]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,274 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,420 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,466 kB]\n",
            "Hit:14 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Fetched 5,696 kB in 3s (2,188 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "cmake is already the newest version (3.22.1-1ubuntu1.22.04.1).\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "The following additional packages will be installed:\n",
            "  freeglut3 libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev libgles1 libglu1-mesa\n",
            "  libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libice-dev libopengl-dev libsm-dev\n",
            "  libxfont2 libxkbfile1 libxt-dev swig4.0 x11-xkb-utils xfonts-base xfonts-encodings xfonts-utils\n",
            "  xserver-common\n",
            "Suggested packages:\n",
            "  libice-doc libsm-doc libxt-doc swig-doc swig-examples swig4.0-examples swig4.0-doc\n",
            "The following NEW packages will be installed:\n",
            "  freeglut3 freeglut3-dev libegl-dev libfontenc1 libgl-dev libgl1-mesa-dev libgles-dev libgles1\n",
            "  libglu1-mesa libglu1-mesa-dev libglvnd-core-dev libglvnd-dev libglx-dev libice-dev libopengl-dev\n",
            "  libsm-dev libxfont2 libxkbfile1 libxt-dev swig swig4.0 x11-xkb-utils xfonts-base xfonts-encodings\n",
            "  xfonts-utils xserver-common xvfb\n",
            "0 upgraded, 27 newly installed, 0 to remove and 19 not upgraded.\n",
            "Need to get 10.2 MB of archives.\n",
            "After this operation, 24.2 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3 amd64 2.8.1-6 [74.0 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglx-dev amd64 1.4.0-1 [14.1 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgl-dev amd64 1.4.0-1 [101 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-core-dev amd64 1.4.0-1 [12.7 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy/main amd64 libegl-dev amd64 1.4.0-1 [18.0 kB]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles1 amd64 1.4.0-1 [11.5 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu jammy/main amd64 libgles-dev amd64 1.4.0-1 [49.4 kB]\n",
            "Get:8 http://archive.ubuntu.com/ubuntu jammy/main amd64 libopengl-dev amd64 1.4.0-1 [3,400 B]\n",
            "Get:9 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglvnd-dev amd64 1.4.0-1 [3,162 B]\n",
            "Get:10 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libgl1-mesa-dev amd64 23.0.4-0ubuntu1~22.04.1 [6,510 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa amd64 9.0.2-1 [145 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy/main amd64 libglu1-mesa-dev amd64 9.0.2-1 [231 kB]\n",
            "Get:13 http://archive.ubuntu.com/ubuntu jammy/main amd64 libice-dev amd64 2:1.0.10-1build2 [51.4 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy/main amd64 libsm-dev amd64 2:1.2.3-1build2 [18.1 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxt-dev amd64 1:1.2.1-1 [396 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy/universe amd64 freeglut3-dev amd64 2.8.1-6 [126 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy/main amd64 libfontenc1 amd64 1:1.1.4-1build3 [14.7 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxfont2 amd64 1:2.0.5-1build1 [94.5 kB]\n",
            "Get:19 http://archive.ubuntu.com/ubuntu jammy/main amd64 libxkbfile1 amd64 1:1.1.0-1build3 [71.8 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig4.0 amd64 4.0.2-1ubuntu1 [1,110 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu jammy/universe amd64 swig all 4.0.2-1ubuntu1 [5,632 B]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu jammy/main amd64 x11-xkb-utils amd64 7.7+5build4 [172 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-encodings all 1:1.0.5-0ubuntu2 [578 kB]\n",
            "Get:24 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-utils amd64 1:7.7+6build2 [94.6 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu jammy/main amd64 xfonts-base all 1:1.0.5 [5,896 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 xserver-common all 2:21.1.4-2ubuntu1.7~22.04.2 [28.1 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 xvfb amd64 2:21.1.4-2ubuntu1.7~22.04.2 [864 kB]\n",
            "Fetched 10.2 MB in 4s (2,867 kB/s)\n",
            "Selecting previously unselected package freeglut3:amd64.\n",
            "(Reading database ... 120874 files and directories currently installed.)\n",
            "Preparing to unpack .../00-freeglut3_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libglx-dev:amd64.\n",
            "Preparing to unpack .../01-libglx-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglx-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl-dev:amd64.\n",
            "Preparing to unpack .../02-libgl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-core-dev:amd64.\n",
            "Preparing to unpack .../03-libglvnd-core-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libegl-dev:amd64.\n",
            "Preparing to unpack .../04-libegl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libegl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles1:amd64.\n",
            "Preparing to unpack .../05-libgles1_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles1:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgles-dev:amd64.\n",
            "Preparing to unpack .../06-libgles-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libgles-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libopengl-dev:amd64.\n",
            "Preparing to unpack .../07-libopengl-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libglvnd-dev:amd64.\n",
            "Preparing to unpack .../08-libglvnd-dev_1.4.0-1_amd64.deb ...\n",
            "Unpacking libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Selecting previously unselected package libgl1-mesa-dev:amd64.\n",
            "Preparing to unpack .../09-libgl1-mesa-dev_23.0.4-0ubuntu1~22.04.1_amd64.deb ...\n",
            "Unpacking libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Selecting previously unselected package libglu1-mesa:amd64.\n",
            "Preparing to unpack .../10-libglu1-mesa_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libglu1-mesa-dev:amd64.\n",
            "Preparing to unpack .../11-libglu1-mesa-dev_9.0.2-1_amd64.deb ...\n",
            "Unpacking libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Selecting previously unselected package libice-dev:amd64.\n",
            "Preparing to unpack .../12-libice-dev_2%3a1.0.10-1build2_amd64.deb ...\n",
            "Unpacking libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Selecting previously unselected package libsm-dev:amd64.\n",
            "Preparing to unpack .../13-libsm-dev_2%3a1.2.3-1build2_amd64.deb ...\n",
            "Unpacking libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Selecting previously unselected package libxt-dev:amd64.\n",
            "Preparing to unpack .../14-libxt-dev_1%3a1.2.1-1_amd64.deb ...\n",
            "Unpacking libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Selecting previously unselected package freeglut3-dev:amd64.\n",
            "Preparing to unpack .../15-freeglut3-dev_2.8.1-6_amd64.deb ...\n",
            "Unpacking freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Selecting previously unselected package libfontenc1:amd64.\n",
            "Preparing to unpack .../16-libfontenc1_1%3a1.1.4-1build3_amd64.deb ...\n",
            "Unpacking libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Selecting previously unselected package libxfont2:amd64.\n",
            "Preparing to unpack .../17-libxfont2_1%3a2.0.5-1build1_amd64.deb ...\n",
            "Unpacking libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Selecting previously unselected package libxkbfile1:amd64.\n",
            "Preparing to unpack .../18-libxkbfile1_1%3a1.1.0-1build3_amd64.deb ...\n",
            "Unpacking libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Selecting previously unselected package swig4.0.\n",
            "Preparing to unpack .../19-swig4.0_4.0.2-1ubuntu1_amd64.deb ...\n",
            "Unpacking swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package swig.\n",
            "Preparing to unpack .../20-swig_4.0.2-1ubuntu1_all.deb ...\n",
            "Unpacking swig (4.0.2-1ubuntu1) ...\n",
            "Selecting previously unselected package x11-xkb-utils.\n",
            "Preparing to unpack .../21-x11-xkb-utils_7.7+5build4_amd64.deb ...\n",
            "Unpacking x11-xkb-utils (7.7+5build4) ...\n",
            "Selecting previously unselected package xfonts-encodings.\n",
            "Preparing to unpack .../22-xfonts-encodings_1%3a1.0.5-0ubuntu2_all.deb ...\n",
            "Unpacking xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Selecting previously unselected package xfonts-utils.\n",
            "Preparing to unpack .../23-xfonts-utils_1%3a7.7+6build2_amd64.deb ...\n",
            "Unpacking xfonts-utils (1:7.7+6build2) ...\n",
            "Selecting previously unselected package xfonts-base.\n",
            "Preparing to unpack .../24-xfonts-base_1%3a1.0.5_all.deb ...\n",
            "Unpacking xfonts-base (1:1.0.5) ...\n",
            "Selecting previously unselected package xserver-common.\n",
            "Preparing to unpack .../25-xserver-common_2%3a21.1.4-2ubuntu1.7~22.04.2_all.deb ...\n",
            "Unpacking xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Selecting previously unselected package xvfb.\n",
            "Preparing to unpack .../26-xvfb_2%3a21.1.4-2ubuntu1.7~22.04.2_amd64.deb ...\n",
            "Unpacking xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up freeglut3:amd64 (2.8.1-6) ...\n",
            "Setting up libglvnd-core-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libice-dev:amd64 (2:1.0.10-1build2) ...\n",
            "Setting up libsm-dev:amd64 (2:1.2.3-1build2) ...\n",
            "Setting up libfontenc1:amd64 (1:1.1.4-1build3) ...\n",
            "Setting up libxt-dev:amd64 (1:1.2.1-1) ...\n",
            "Setting up libgles1:amd64 (1.4.0-1) ...\n",
            "Setting up xfonts-encodings (1:1.0.5-0ubuntu2) ...\n",
            "Setting up libglx-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libglu1-mesa:amd64 (9.0.2-1) ...\n",
            "Setting up libxkbfile1:amd64 (1:1.1.0-1build3) ...\n",
            "Setting up libopengl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up swig4.0 (4.0.2-1ubuntu1) ...\n",
            "Setting up libxfont2:amd64 (1:2.0.5-1build1) ...\n",
            "Setting up libgl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up swig (4.0.2-1ubuntu1) ...\n",
            "Setting up libegl-dev:amd64 (1.4.0-1) ...\n",
            "Setting up x11-xkb-utils (7.7+5build4) ...\n",
            "Setting up xfonts-utils (1:7.7+6build2) ...\n",
            "Setting up xfonts-base (1:1.0.5) ...\n",
            "Setting up libglu1-mesa-dev:amd64 (9.0.2-1) ...\n",
            "Setting up xserver-common (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up libgles-dev:amd64 (1.4.0-1) ...\n",
            "Setting up xvfb (2:21.1.4-2ubuntu1.7~22.04.2) ...\n",
            "Setting up libglvnd-dev:amd64 (1.4.0-1) ...\n",
            "Setting up libgl1-mesa-dev:amd64 (23.0.4-0ubuntu1~22.04.1) ...\n",
            "Setting up freeglut3-dev:amd64 (2.8.1-6) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.1) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for fontconfig (2.13.1-4.2ubuntu5) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get update && apt-get install swig cmake ffmpeg freeglut3-dev xvfb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDjF3qRg7oGH"
      },
      "source": [
        "## Clone RL Baselines3 Zoo Repo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCjGikdT1DFy",
        "outputId": "f3d3a968-f3e0-4e4d-e273-19ee420e04a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'rl-baselines3-zoo'...\n",
            "remote: Enumerating objects: 5395, done.\u001b[K\n",
            "remote: Counting objects: 100% (241/241), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 5395 (delta 130), reused 151 (delta 84), pack-reused 5154\u001b[K\n",
            "Receiving objects: 100% (5395/5395), 3.84 MiB | 8.44 MiB/s, done.\n",
            "Resolving deltas: 100% (3548/3548), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/DLR-RM/rl-baselines3-zoo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "REMQlh-ezyVt",
        "outputId": "a86772ab-bcf3-408d-b018-26265f7b1655"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/rl-baselines3-zoo\n"
          ]
        }
      ],
      "source": [
        "%cd /content/rl-baselines3-zoo/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5tmD_QTBqTMb"
      },
      "source": [
        "### Install pip dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OWIDzgJTqShY",
        "outputId": "97b3588c-ddce-4b6f-85ed-702462b73612"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gym==0.26.2 (from -r requirements.txt (line 1))\n",
            "  Downloading gym-0.26.2.tar.gz (721 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/721.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m348.2/721.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m721.7/721.7 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11 (from -r requirements.txt (line 2))\n",
            "  Downloading stable_baselines3-2.2.0a11-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.7/181.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sb3-contrib<3.0,>=2.2.0a11 (from -r requirements.txt (line 3))\n",
            "  Downloading sb3_contrib-2.2.0a11-py3-none-any.whl (80 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.7/80.7 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting box2d-py==2.3.8 (from -r requirements.txt (line 4))\n",
            "  Downloading box2d-py-2.3.8.tar.gz (374 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m374.5/374.5 kB\u001b[0m \u001b[31m33.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybullet (from -r requirements.txt (line 5))\n",
            "  Downloading pybullet-3.2.5.tar.gz (80.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.5/80.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pybullet_envs_gymnasium>=0.4.0 (from -r requirements.txt (line 6))\n",
            "  Downloading pybullet_envs_gymnasium-0.4.0-py3-none-any.whl (22 kB)\n",
            "Collecting optuna~=3.0 (from -r requirements.txt (line 9))\n",
            "  Downloading optuna-3.4.0-py3-none-any.whl (409 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m409.6/409.6 kB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter~=0.64 (from -r requirements.txt (line 10))\n",
            "  Downloading pytablewriter-0.64.2-py3-none-any.whl (106 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.6/106.6 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (6.0.1)\n",
            "Requirement already satisfied: cloudpickle>=2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (2.2.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 13)) (5.15.0)\n",
            "Collecting rliable>=1.0.5 (from -r requirements.txt (line 16))\n",
            "  Downloading rliable-1.0.8-py3-none-any.whl (19 kB)\n",
            "Collecting wandb (from -r requirements.txt (line 17))\n",
            "  Downloading wandb-0.16.0-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface_sb3<4.0,>=3.0 (from -r requirements.txt (line 18))\n",
            "  Downloading huggingface_sb3-3.0-py3-none-any.whl (9.7 kB)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (0.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (4.66.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (13.6.0)\n",
            "Requirement already satisfied: moviepy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (1.0.3)\n",
            "Collecting ruff (from -r requirements.txt (line 23))\n",
            "  Downloading ruff-0.1.5-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m88.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.18.0 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->-r requirements.txt (line 1)) (1.23.5)\n",
            "Requirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from gym==0.26.2->-r requirements.txt (line 1)) (0.0.8)\n",
            "Collecting gymnasium<0.30,>=0.28.1 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading gymnasium-0.29.1-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.9/953.9 kB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch>=1.13 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.1.0+cu118)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.5.3)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (4.8.0.76)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.5.2)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.14.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (5.9.5)\n",
            "Collecting shimmy[atari]~=1.3.0 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (9.4.0)\n",
            "Requirement already satisfied: sphinx<8,>=5 in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (5.0.2)\n",
            "Collecting sphinx-autobuild (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading sphinx_autobuild-2021.3.14-py3-none-any.whl (9.9 kB)\n",
            "Collecting sphinx-rtd-theme>=1.3.0 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading sphinx_rtd_theme-1.3.0-py2.py3-none-any.whl (2.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m83.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sphinxcontrib.spelling (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading sphinxcontrib_spelling-8.0.0-py3-none-any.whl (16 kB)\n",
            "Collecting sphinx-copybutton (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading sphinx_copybutton-0.5.2-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.10/dist-packages (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (7.4.3)\n",
            "Collecting pytest-cov (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading pytest_cov-4.1.0-py3-none-any.whl (21 kB)\n",
            "Collecting pytest-env (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading pytest_env-1.1.1-py3-none-any.whl (6.2 kB)\n",
            "Collecting pytest-xdist (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading pytest_xdist-3.3.1-py3-none-any.whl (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.8/41.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mypy (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading mypy-1.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.5/12.5 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting black<24,>=23.9.1 (from stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading black-23.11.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m75.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting alembic>=1.5.0 (from optuna~=3.0->-r requirements.txt (line 9))\n",
            "  Downloading alembic-1.12.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.8/226.8 kB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorlog (from optuna~=3.0->-r requirements.txt (line 9))\n",
            "  Downloading colorlog-6.7.0-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from optuna~=3.0->-r requirements.txt (line 9)) (23.2)\n",
            "Requirement already satisfied: sqlalchemy>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from optuna~=3.0->-r requirements.txt (line 9)) (2.0.23)\n",
            "Requirement already satisfied: setuptools>=38.3.0 in /usr/local/lib/python3.10/dist-packages (from pytablewriter~=0.64->-r requirements.txt (line 10)) (67.7.2)\n",
            "Collecting DataProperty<2,>=0.55.0 (from pytablewriter~=0.64->-r requirements.txt (line 10))\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter~=0.64->-r requirements.txt (line 10))\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<3,>=2.3.0 (from pytablewriter~=0.64->-r requirements.txt (line 10))\n",
            "  Downloading pathvalidate-2.5.2-py3-none-any.whl (20 kB)\n",
            "Collecting tabledata<2,>=1.3.0 (from pytablewriter~=0.64->-r requirements.txt (line 10))\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter~=0.64->-r requirements.txt (line 10))\n",
            "  Downloading tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.2.0 (from pytablewriter~=0.64->-r requirements.txt (line 10))\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->-r requirements.txt (line 13)) (8.2.3)\n",
            "Collecting arch==5.3.0 (from rliable>=1.0.5->-r requirements.txt (line 16))\n",
            "  Downloading arch-5.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (905 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m905.4/905.4 kB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from rliable>=1.0.5->-r requirements.txt (line 16)) (1.11.3)\n",
            "Requirement already satisfied: absl-py>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from rliable>=1.0.5->-r requirements.txt (line 16)) (1.4.0)\n",
            "Requirement already satisfied: statsmodels>=0.11 in /usr/local/lib/python3.10/dist-packages (from arch==5.3.0->rliable>=1.0.5->-r requirements.txt (line 16)) (0.14.0)\n",
            "Collecting property-cached>=1.6.4 (from arch==5.3.0->rliable>=1.0.5->-r requirements.txt (line 16))\n",
            "  Downloading property_cached-1.6.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 17)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 17))\n",
            "  Downloading GitPython-3.1.40-py3-none-any.whl (190 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 17)) (2.31.0)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 17))\n",
            "  Downloading sentry_sdk-1.34.0-py2.py3-none-any.whl (243 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 17))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 17))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 17)) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 17)) (3.20.3)\n",
            "Collecting huggingface-hub~=0.8 (from huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 18))\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wasabi in /usr/local/lib/python3.10/dist-packages (from huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 18)) (1.1.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 21)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 21)) (2.16.1)\n",
            "Requirement already satisfied: decorator<5.0,>=4.0.2 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 22)) (4.4.2)\n",
            "Requirement already satisfied: proglog<=1.0.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 22)) (0.1.10)\n",
            "Requirement already satisfied: imageio<3.0,>=2.5 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 22)) (2.31.6)\n",
            "Requirement already satisfied: imageio-ffmpeg>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from moviepy->-r requirements.txt (line 22)) (0.4.9)\n",
            "Collecting Mako (from alembic>=1.5.0->optuna~=3.0->-r requirements.txt (line 9))\n",
            "  Downloading Mako-1.3.0-py3-none-any.whl (78 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic>=1.5.0->optuna~=3.0->-r requirements.txt (line 9)) (4.5.0)\n",
            "Collecting mypy-extensions>=0.4.3 (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Collecting pathspec>=0.9.0 (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading pathspec-0.11.2-py3-none-any.whl (29 kB)\n",
            "Requirement already satisfied: platformdirs>=2 in /usr/local/lib/python3.10/dist-packages (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.11.0)\n",
            "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from black<24,>=23.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.0.1)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb->-r requirements.txt (line 17)) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 17))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting farama-notifications>=0.0.1 (from gymnasium<0.30,>=0.28.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 18)) (3.13.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub~=0.8->huggingface_sb3<4.0,>=3.0->-r requirements.txt (line 18)) (2023.6.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 21)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (4.44.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter~=0.64->-r requirements.txt (line 10)) (5.2.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2023.3.post1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 17)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 17)) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 17)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb->-r requirements.txt (line 17)) (2023.7.22)\n",
            "Collecting ale-py~=0.8.1 (from shimmy[atari]~=1.3.0->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading ale_py-0.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sphinxcontrib-applehelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.0.7)\n",
            "Requirement already satisfied: sphinxcontrib-devhelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.0.5)\n",
            "Requirement already satisfied: sphinxcontrib-jsmath in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: sphinxcontrib-htmlhelp>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.0.4)\n",
            "Requirement already satisfied: sphinxcontrib-serializinghtml>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.1.9)\n",
            "Requirement already satisfied: sphinxcontrib-qthelp in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.0.6)\n",
            "Requirement already satisfied: Jinja2>=2.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.1.2)\n",
            "Requirement already satisfied: docutils<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (0.18.1)\n",
            "Requirement already satisfied: snowballstemmer>=1.1 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.2.0)\n",
            "Requirement already satisfied: babel>=1.3 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.13.1)\n",
            "Requirement already satisfied: alabaster<0.8,>=0.7 in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (0.7.13)\n",
            "Requirement already satisfied: imagesize in /usr/local/lib/python3.10/dist-packages (from sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.4.1)\n",
            "Collecting sphinxcontrib-jquery<5,>=4 (from sphinx-rtd-theme>=1.3.0->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy>=1.3.0->optuna~=3.0->-r requirements.txt (line 9)) (3.0.1)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.59.2)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.5.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.0.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.1.0)\n",
            "Requirement already satisfied: iniconfig in /usr/local/lib/python3.10/dist-packages (from pytest->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.0.0)\n",
            "Requirement already satisfied: pluggy<2.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from pytest->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in /usr/local/lib/python3.10/dist-packages (from pytest->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.1.3)\n",
            "Collecting coverage[toml]>=5.2.1 (from pytest-cov->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading coverage-7.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.5/227.5 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting execnet>=1.1 (from pytest-xdist->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading execnet-2.0.2-py3-none-any.whl (37 kB)\n",
            "Collecting livereload (from sphinx-autobuild->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading livereload-2.6.3-py2.py3-none-any.whl (24 kB)\n",
            "Collecting colorama (from sphinx-autobuild->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting PyEnchant>=3.1.1 (from sphinxcontrib.spelling->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2))\n",
            "  Downloading pyenchant-3.2.2-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (6.1.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 17))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=2.3->sphinx<8,>=5->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (2.1.3)\n",
            "Requirement already satisfied: patsy>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.11->arch==5.3.0->rliable>=1.0.5->-r requirements.txt (line 16)) (0.5.3)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.10/dist-packages (from livereload->sphinx-autobuild->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (6.3.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard>=2.9.1->stable-baselines3[docs,extra_no_roms,tests]<3.0,>=2.2.0a11->-r requirements.txt (line 2)) (3.2.2)\n",
            "Building wheels for collected packages: gym, box2d-py, pybullet\n",
            "  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gym: filename=gym-0.26.2-py3-none-any.whl size=827622 sha256=cd2f98c322a1bac9d10b64c8a3791b7d60356614a54b8e2753912fc4332193ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/22/6d/3e7b32d98451b4cd9d12417052affbeeeea012955d437da1da\n",
            "  Building wheel for box2d-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for box2d-py: filename=box2d_py-2.3.8-cp310-cp310-linux_x86_64.whl size=2349116 sha256=88c67bd354117611e58285b57e1707f9e4f25ed5c2c1d6dc5422703f89fd2e3a\n",
            "  Stored in directory: /root/.cache/pip/wheels/47/01/d2/6a780da77ccb98b1d2facdd520a8d10838a03b590f6f8d50c0\n",
            "  Building wheel for pybullet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pybullet: filename=pybullet-3.2.5-cp310-cp310-linux_x86_64.whl size=99850151 sha256=452f903c8511bba24285fbc3fc31ae2ac6e6a5828d14cabc371166ae59566815\n",
            "  Stored in directory: /root/.cache/pip/wheels/6b/fa/1a/c315a5133f0c9bf202a6daa5d70891120e7fe403e06e3407cc\n",
            "Successfully built gym box2d-py pybullet\n",
            "Installing collected packages: pybullet, farama-notifications, box2d-py, tcolorpy, smmap, setproctitle, sentry-sdk, ruff, PyEnchant, property-cached, pathvalidate, pathspec, mypy-extensions, mbstrdecoder, Mako, livereload, gymnasium, gym, execnet, docker-pycreds, coverage, colorlog, colorama, ale-py, typepy, shimmy, pytest-xdist, pytest-env, pybullet_envs_gymnasium, mypy, huggingface-hub, gitdb, black, alembic, stable-baselines3, pytest-cov, optuna, huggingface_sb3, GitPython, wandb, sb3-contrib, DataProperty, arch, tabledata, rliable, pytablewriter, sphinxcontrib-jquery, sphinxcontrib.spelling, sphinx-rtd-theme, sphinx-copybutton, sphinx-autobuild\n",
            "  Attempting uninstall: gym\n",
            "    Found existing installation: gym 0.25.2\n",
            "    Uninstalling gym-0.25.2:\n",
            "      Successfully uninstalled gym-0.25.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "dopamine-rl 4.0.6 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.0.1 GitPython-3.1.40 Mako-1.3.0 PyEnchant-3.2.2 ale-py-0.8.1 alembic-1.12.1 arch-5.3.0 black-23.11.0 box2d-py-2.3.8 colorama-0.4.6 colorlog-6.7.0 coverage-7.3.2 docker-pycreds-0.4.0 execnet-2.0.2 farama-notifications-0.0.4 gitdb-4.0.11 gym-0.26.2 gymnasium-0.29.1 huggingface-hub-0.19.0 huggingface_sb3-3.0 livereload-2.6.3 mbstrdecoder-1.1.3 mypy-1.7.0 mypy-extensions-1.0.0 optuna-3.4.0 pathspec-0.11.2 pathvalidate-2.5.2 property-cached-1.6.4 pybullet-3.2.5 pybullet_envs_gymnasium-0.4.0 pytablewriter-0.64.2 pytest-cov-4.1.0 pytest-env-1.1.1 pytest-xdist-3.3.1 rliable-1.0.8 ruff-0.1.5 sb3-contrib-2.2.0a11 sentry-sdk-1.34.0 setproctitle-1.3.3 shimmy-1.3.0 smmap-5.0.1 sphinx-autobuild-2021.3.14 sphinx-copybutton-0.5.2 sphinx-rtd-theme-1.3.0 sphinxcontrib-jquery-4.1 sphinxcontrib.spelling-8.0.0 stable-baselines3-2.2.0a11 tabledata-1.3.3 tcolorpy-0.1.4 typepy-1.3.2 wandb-0.16.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gJ-pAbF7zRZ"
      },
      "source": [
        "## Train an RL Agent\n",
        "\n",
        "\n",
        "The train agent can be found in the `logs/` folder.\n",
        "\n",
        "Here we will train A2C on CartPole-v1 environment for 100 000 steps.\n",
        "\n",
        "\n",
        "To train it on Pong (Atari), you just have to pass `--env PongNoFrameskip-v4`\n",
        "\n",
        "Note: You need to update `hyperparams/algo.yml` to support new environments. You can access it in the side panel of Google Colab. (see https://stackoverflow.com/questions/46986398/import-data-into-google-colaboratory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bIR_N7R11XI",
        "outputId": "c839b729-13ca-4b52-835b-f0eb24304fb5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-10 15:49:45.116640: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-10 15:49:45.116700: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-10 15:49:45.116740: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-10 15:49:45.125088: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-10 15:49:46.245434: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "========== CartPole-v1 ==========\n",
            "Seed: 4109119834\n",
            "Loading hyperparameters from: /content/rl-baselines3-zoo/hyperparams/a2c.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('ent_coef', 0.0),\n",
            "             ('n_envs', 8),\n",
            "             ('n_timesteps', 500000.0),\n",
            "             ('policy', 'MlpPolicy')])\n",
            "Using 8 environments\n",
            "Overwriting n_timesteps with n=100000\n",
            "Creating test environment\n",
            "Using cuda device\n",
            "Log path: logs/a2c/CartPole-v1_1\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 30.9     |\n",
            "|    ep_rew_mean        | 30.9     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1013     |\n",
            "|    iterations         | 100      |\n",
            "|    time_elapsed       | 3        |\n",
            "|    total_timesteps    | 4000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.6     |\n",
            "|    explained_variance | 0.243    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 99       |\n",
            "|    policy_loss        | 1.18     |\n",
            "|    value_loss         | 7.14     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 46.6     |\n",
            "|    ep_rew_mean        | 46.6     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1548     |\n",
            "|    iterations         | 200      |\n",
            "|    time_elapsed       | 5        |\n",
            "|    total_timesteps    | 8000     |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.552   |\n",
            "|    explained_variance | 0.561    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 199      |\n",
            "|    policy_loss        | 1.37     |\n",
            "|    value_loss         | 6.51     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 83.1     |\n",
            "|    ep_rew_mean        | 83.1     |\n",
            "| time/                 |          |\n",
            "|    fps                | 1887     |\n",
            "|    iterations         | 300      |\n",
            "|    time_elapsed       | 6        |\n",
            "|    total_timesteps    | 12000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.541   |\n",
            "|    explained_variance | 0.00664  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 299      |\n",
            "|    policy_loss        | 0.399    |\n",
            "|    value_loss         | 34.4     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 103      |\n",
            "|    ep_rew_mean        | 103      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2128     |\n",
            "|    iterations         | 400      |\n",
            "|    time_elapsed       | 7        |\n",
            "|    total_timesteps    | 16000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.551   |\n",
            "|    explained_variance | -0.00163 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 399      |\n",
            "|    policy_loss        | 1.04     |\n",
            "|    value_loss         | 5.14     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 144      |\n",
            "|    ep_rew_mean        | 144      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2294     |\n",
            "|    iterations         | 500      |\n",
            "|    time_elapsed       | 8        |\n",
            "|    total_timesteps    | 20000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.529   |\n",
            "|    explained_variance | 0.00343  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 499      |\n",
            "|    policy_loss        | 0.758    |\n",
            "|    value_loss         | 4.56     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 174      |\n",
            "|    ep_rew_mean        | 174      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2405     |\n",
            "|    iterations         | 600      |\n",
            "|    time_elapsed       | 9        |\n",
            "|    total_timesteps    | 24000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.531   |\n",
            "|    explained_variance | -0.0056  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 599      |\n",
            "|    policy_loss        | 0.856    |\n",
            "|    value_loss         | 3.95     |\n",
            "------------------------------------\n",
            "Eval num_timesteps=25000, episode_reward=500.00 +/- 0.00\n",
            "Episode length: 500.00 +/- 0.00\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 500      |\n",
            "|    mean_reward        | 500      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 25000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.502   |\n",
            "|    explained_variance | 0.00485  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 624      |\n",
            "|    policy_loss        | 0.948    |\n",
            "|    value_loss         | 3.78     |\n",
            "------------------------------------\n",
            "New best mean reward!\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 214      |\n",
            "|    ep_rew_mean        | 214      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2044     |\n",
            "|    iterations         | 700      |\n",
            "|    time_elapsed       | 13       |\n",
            "|    total_timesteps    | 28000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.479   |\n",
            "|    explained_variance | 0.00063  |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 699      |\n",
            "|    policy_loss        | 1.06     |\n",
            "|    value_loss         | 3.42     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 240      |\n",
            "|    ep_rew_mean        | 240      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2063     |\n",
            "|    iterations         | 800      |\n",
            "|    time_elapsed       | 15       |\n",
            "|    total_timesteps    | 32000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.496   |\n",
            "|    explained_variance | 2.03e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 799      |\n",
            "|    policy_loss        | 0.795    |\n",
            "|    value_loss         | 2.97     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 255      |\n",
            "|    ep_rew_mean        | 255      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2102     |\n",
            "|    iterations         | 900      |\n",
            "|    time_elapsed       | 17       |\n",
            "|    total_timesteps    | 36000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.525   |\n",
            "|    explained_variance | 0.000422 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 899      |\n",
            "|    policy_loss        | 0.627    |\n",
            "|    value_loss         | 2.58     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 269      |\n",
            "|    ep_rew_mean        | 269      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2185     |\n",
            "|    iterations         | 1000     |\n",
            "|    time_elapsed       | 18       |\n",
            "|    total_timesteps    | 40000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.462   |\n",
            "|    explained_variance | 0.000295 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 999      |\n",
            "|    policy_loss        | 0.726    |\n",
            "|    value_loss         | 2.2      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 302       |\n",
            "|    ep_rew_mean        | 302       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2258      |\n",
            "|    iterations         | 1100      |\n",
            "|    time_elapsed       | 19        |\n",
            "|    total_timesteps    | 44000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.506    |\n",
            "|    explained_variance | -0.000693 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1099      |\n",
            "|    policy_loss        | 0.629     |\n",
            "|    value_loss         | 1.84      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 296       |\n",
            "|    ep_rew_mean        | 296       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2326      |\n",
            "|    iterations         | 1200      |\n",
            "|    time_elapsed       | 20        |\n",
            "|    total_timesteps    | 48000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.595    |\n",
            "|    explained_variance | -0.000182 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1199      |\n",
            "|    policy_loss        | 0.613     |\n",
            "|    value_loss         | 1.55      |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=50000, episode_reward=224.20 +/- 26.75\n",
            "Episode length: 224.20 +/- 26.75\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 224      |\n",
            "|    mean_reward        | 224      |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 50000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.606   |\n",
            "|    explained_variance | 2.85e-05 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1249     |\n",
            "|    policy_loss        | 0.547    |\n",
            "|    value_loss         | 1.43     |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 251       |\n",
            "|    ep_rew_mean        | 251       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2289      |\n",
            "|    iterations         | 1300      |\n",
            "|    time_elapsed       | 22        |\n",
            "|    total_timesteps    | 52000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.567    |\n",
            "|    explained_variance | -0.000168 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1299      |\n",
            "|    policy_loss        | 0.525     |\n",
            "|    value_loss         | 1.34      |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 228       |\n",
            "|    ep_rew_mean        | 228       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2340      |\n",
            "|    iterations         | 1400      |\n",
            "|    time_elapsed       | 23        |\n",
            "|    total_timesteps    | 56000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.523    |\n",
            "|    explained_variance | -5.35e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1399      |\n",
            "|    policy_loss        | -3.39     |\n",
            "|    value_loss         | 424       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 217       |\n",
            "|    ep_rew_mean        | 217       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2389      |\n",
            "|    iterations         | 1500      |\n",
            "|    time_elapsed       | 25        |\n",
            "|    total_timesteps    | 60000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.516    |\n",
            "|    explained_variance | -2.26e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1499      |\n",
            "|    policy_loss        | -1.36     |\n",
            "|    value_loss         | 239       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 172       |\n",
            "|    ep_rew_mean        | 172       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2436      |\n",
            "|    iterations         | 1600      |\n",
            "|    time_elapsed       | 26        |\n",
            "|    total_timesteps    | 64000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.526    |\n",
            "|    explained_variance | -0.000222 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1599      |\n",
            "|    policy_loss        | 0.369     |\n",
            "|    value_loss         | 0.777     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 163       |\n",
            "|    ep_rew_mean        | 163       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2451      |\n",
            "|    iterations         | 1700      |\n",
            "|    time_elapsed       | 27        |\n",
            "|    total_timesteps    | 68000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.548    |\n",
            "|    explained_variance | -0.000107 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1699      |\n",
            "|    policy_loss        | 0.375     |\n",
            "|    value_loss         | 0.638     |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 158       |\n",
            "|    ep_rew_mean        | 158       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2447      |\n",
            "|    iterations         | 1800      |\n",
            "|    time_elapsed       | 29        |\n",
            "|    total_timesteps    | 72000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.515    |\n",
            "|    explained_variance | -3.89e-05 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1799      |\n",
            "|    policy_loss        | 0.323     |\n",
            "|    value_loss         | 0.503     |\n",
            "-------------------------------------\n",
            "Eval num_timesteps=75000, episode_reward=151.20 +/- 21.03\n",
            "Episode length: 151.20 +/- 21.03\n",
            "-------------------------------------\n",
            "| eval/                 |           |\n",
            "|    mean_ep_length     | 151       |\n",
            "|    mean_reward        | 151       |\n",
            "| time/                 |           |\n",
            "|    total_timesteps    | 75000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.498    |\n",
            "|    explained_variance | -7.39e-06 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1874      |\n",
            "|    policy_loss        | 0.256     |\n",
            "|    value_loss         | 0.422     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 147      |\n",
            "|    ep_rew_mean        | 147      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2365     |\n",
            "|    iterations         | 1900     |\n",
            "|    time_elapsed       | 32       |\n",
            "|    total_timesteps    | 76000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.491   |\n",
            "|    explained_variance | -3.7e-06 |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 1899     |\n",
            "|    policy_loss        | -1.63    |\n",
            "|    value_loss         | 314      |\n",
            "------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 154       |\n",
            "|    ep_rew_mean        | 154       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2401      |\n",
            "|    iterations         | 2000      |\n",
            "|    time_elapsed       | 33        |\n",
            "|    total_timesteps    | 80000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.514    |\n",
            "|    explained_variance | -2.98e-06 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 1999      |\n",
            "|    policy_loss        | -1.87     |\n",
            "|    value_loss         | 338       |\n",
            "-------------------------------------\n",
            "-------------------------------------\n",
            "| rollout/              |           |\n",
            "|    ep_len_mean        | 169       |\n",
            "|    ep_rew_mean        | 169       |\n",
            "| time/                 |           |\n",
            "|    fps                | 2433      |\n",
            "|    iterations         | 2100      |\n",
            "|    time_elapsed       | 34        |\n",
            "|    total_timesteps    | 84000     |\n",
            "| train/                |           |\n",
            "|    entropy_loss       | -0.575    |\n",
            "|    explained_variance | -0.000133 |\n",
            "|    learning_rate      | 0.0007    |\n",
            "|    n_updates          | 2099      |\n",
            "|    policy_loss        | 0.167     |\n",
            "|    value_loss         | 0.165     |\n",
            "-------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 198      |\n",
            "|    ep_rew_mean        | 198      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2463     |\n",
            "|    iterations         | 2200     |\n",
            "|    time_elapsed       | 35       |\n",
            "|    total_timesteps    | 88000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.439   |\n",
            "|    explained_variance | 0.0825   |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2199     |\n",
            "|    policy_loss        | 0.132    |\n",
            "|    value_loss         | 0.0763   |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 200      |\n",
            "|    ep_rew_mean        | 200      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2495     |\n",
            "|    iterations         | 2300     |\n",
            "|    time_elapsed       | 36       |\n",
            "|    total_timesteps    | 92000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.505   |\n",
            "|    explained_variance | 0.997    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2299     |\n",
            "|    policy_loss        | -0.332   |\n",
            "|    value_loss         | 19.2     |\n",
            "------------------------------------\n",
            "------------------------------------\n",
            "| rollout/              |          |\n",
            "|    ep_len_mean        | 143      |\n",
            "|    ep_rew_mean        | 143      |\n",
            "| time/                 |          |\n",
            "|    fps                | 2525     |\n",
            "|    iterations         | 2400     |\n",
            "|    time_elapsed       | 38       |\n",
            "|    total_timesteps    | 96000    |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.479   |\n",
            "|    explained_variance | 0.857    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2399     |\n",
            "|    policy_loss        | -2.89    |\n",
            "|    value_loss         | 198      |\n",
            "------------------------------------\n",
            "Eval num_timesteps=100000, episode_reward=39.20 +/- 4.02\n",
            "Episode length: 39.20 +/- 4.02\n",
            "------------------------------------\n",
            "| eval/                 |          |\n",
            "|    mean_ep_length     | 39.2     |\n",
            "|    mean_reward        | 39.2     |\n",
            "| time/                 |          |\n",
            "|    total_timesteps    | 100000   |\n",
            "| train/                |          |\n",
            "|    entropy_loss       | -0.515   |\n",
            "|    explained_variance | 0.982    |\n",
            "|    learning_rate      | 0.0007   |\n",
            "|    n_updates          | 2499     |\n",
            "|    policy_loss        | -1.05    |\n",
            "|    value_loss         | 12.9     |\n",
            "------------------------------------\n",
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 47.3     |\n",
            "|    ep_rew_mean     | 47.3     |\n",
            "| time/              |          |\n",
            "|    fps             | 2540     |\n",
            "|    iterations      | 2500     |\n",
            "|    time_elapsed    | 39       |\n",
            "|    total_timesteps | 100000   |\n",
            "---------------------------------\n",
            "Saving to logs/a2c/CartPole-v1_1\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo a2c --env CartPole-v1 --n-timesteps 100000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-fHBq73665yD"
      },
      "source": [
        "#### Evaluate trained agent\n",
        "\n",
        "\n",
        "You can remove the `--folder logs/` to evaluate pretrained agent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bw8YuEgU6bT3",
        "outputId": "3981d07c-e5b1-4c5e-84e3-cbb70adc2098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-10 15:53:04.089326: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-10 15:53:04.089388: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-10 15:53:04.089430: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-10 15:53:04.097167: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-10 15:53:05.185744: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "Loading latest experiment, id=1\n",
            "Loading logs/a2c/CartPole-v1_1/CartPole-v1.zip\n",
            "Episode Reward: 31.00\n",
            "Episode Length 31\n",
            "Episode Reward: 56.00\n",
            "Episode Length 56\n",
            "Episode Reward: 58.00\n",
            "Episode Length 58\n",
            "Episode Reward: 52.00\n",
            "Episode Length 52\n",
            "Episode Reward: 37.00\n",
            "Episode Length 37\n",
            "Episode Reward: 49.00\n",
            "Episode Length 49\n",
            "Episode Reward: 53.00\n",
            "Episode Length 53\n",
            "Episode Reward: 56.00\n",
            "Episode Length 56\n",
            "Episode Reward: 43.00\n",
            "Episode Length 43\n",
            "Episode Reward: 63.00\n",
            "Episode Length 63\n",
            "Episode Reward: 47.00\n",
            "Episode Length 47\n",
            "Episode Reward: 38.00\n",
            "Episode Length 38\n",
            "Episode Reward: 58.00\n",
            "Episode Length 58\n",
            "Episode Reward: 37.00\n",
            "Episode Length 37\n",
            "Episode Reward: 36.00\n",
            "Episode Length 36\n",
            "Episode Reward: 33.00\n",
            "Episode Length 33\n",
            "Episode Reward: 40.00\n",
            "Episode Length 40\n",
            "Episode Reward: 47.00\n",
            "Episode Length 47\n",
            "Episode Reward: 46.00\n",
            "Episode Length 46\n",
            "Episode Reward: 58.00\n",
            "Episode Length 58\n",
            "Episode Reward: 50.00\n",
            "Episode Length 50\n",
            "Episode Reward: 51.00\n",
            "Episode Length 51\n",
            "Episode Reward: 53.00\n",
            "Episode Length 53\n",
            "Episode Reward: 54.00\n",
            "Episode Length 54\n",
            "Episode Reward: 53.00\n",
            "Episode Length 53\n",
            "Episode Reward: 49.00\n",
            "Episode Length 49\n",
            "Episode Reward: 47.00\n",
            "Episode Length 47\n",
            "Episode Reward: 43.00\n",
            "Episode Length 43\n",
            "Episode Reward: 60.00\n",
            "Episode Length 60\n",
            "Episode Reward: 58.00\n",
            "Episode Length 58\n",
            "Episode Reward: 53.00\n",
            "Episode Length 53\n",
            "Episode Reward: 55.00\n",
            "Episode Length 55\n",
            "Episode Reward: 48.00\n",
            "Episode Length 48\n",
            "Episode Reward: 40.00\n",
            "Episode Length 40\n",
            "Episode Reward: 60.00\n",
            "Episode Length 60\n",
            "Episode Reward: 62.00\n",
            "Episode Length 62\n",
            "Episode Reward: 35.00\n",
            "Episode Length 35\n",
            "Episode Reward: 34.00\n",
            "Episode Length 34\n",
            "Episode Reward: 38.00\n",
            "Episode Length 38\n",
            "Episode Reward: 62.00\n",
            "Episode Length 62\n",
            "Episode Reward: 49.00\n",
            "Episode Length 49\n",
            "Episode Reward: 39.00\n",
            "Episode Length 39\n",
            "Episode Reward: 44.00\n",
            "Episode Length 44\n",
            "Episode Reward: 48.00\n",
            "Episode Length 48\n",
            "Episode Reward: 58.00\n",
            "Episode Length 58\n",
            "Episode Reward: 35.00\n",
            "Episode Length 35\n",
            "Episode Reward: 44.00\n",
            "Episode Length 44\n",
            "Episode Reward: 36.00\n",
            "Episode Length 36\n",
            "Episode Reward: 52.00\n",
            "Episode Length 52\n",
            "Episode Reward: 52.00\n",
            "Episode Length 52\n",
            "Episode Reward: 49.00\n",
            "Episode Length 49\n",
            "Episode Reward: 65.00\n",
            "Episode Length 65\n",
            "Episode Reward: 35.00\n",
            "Episode Length 35\n",
            "Episode Reward: 32.00\n",
            "Episode Length 32\n",
            "Episode Reward: 54.00\n",
            "Episode Length 54\n",
            "Episode Reward: 32.00\n",
            "Episode Length 32\n",
            "Episode Reward: 42.00\n",
            "Episode Length 42\n",
            "Episode Reward: 55.00\n",
            "Episode Length 55\n",
            "Episode Reward: 35.00\n",
            "Episode Length 35\n",
            "Episode Reward: 49.00\n",
            "Episode Length 49\n",
            "Episode Reward: 60.00\n",
            "Episode Length 60\n",
            "Episode Reward: 62.00\n",
            "Episode Length 62\n",
            "Episode Reward: 39.00\n",
            "Episode Length 39\n",
            "Episode Reward: 47.00\n",
            "Episode Length 47\n",
            "Episode Reward: 57.00\n",
            "Episode Length 57\n",
            "Episode Reward: 59.00\n",
            "Episode Length 59\n",
            "Episode Reward: 44.00\n",
            "Episode Length 44\n",
            "Episode Reward: 48.00\n",
            "Episode Length 48\n",
            "Episode Reward: 48.00\n",
            "Episode Length 48\n",
            "Episode Reward: 54.00\n",
            "Episode Length 54\n",
            "Episode Reward: 61.00\n",
            "Episode Length 61\n",
            "Episode Reward: 42.00\n",
            "Episode Length 42\n",
            "Episode Reward: 37.00\n",
            "Episode Length 37\n",
            "Episode Reward: 43.00\n",
            "Episode Length 43\n",
            "Episode Reward: 51.00\n",
            "Episode Length 51\n",
            "Episode Reward: 34.00\n",
            "Episode Length 34\n",
            "Episode Reward: 52.00\n",
            "Episode Length 52\n",
            "Episode Reward: 35.00\n",
            "Episode Length 35\n",
            "Episode Reward: 48.00\n",
            "Episode Length 48\n",
            "Episode Reward: 37.00\n",
            "Episode Length 37\n",
            "Episode Reward: 70.00\n",
            "Episode Length 70\n",
            "Episode Reward: 38.00\n",
            "Episode Length 38\n",
            "Episode Reward: 57.00\n",
            "Episode Length 57\n",
            "Episode Reward: 37.00\n",
            "Episode Length 37\n",
            "Episode Reward: 38.00\n",
            "Episode Length 38\n",
            "Episode Reward: 53.00\n",
            "Episode Length 53\n",
            "Episode Reward: 35.00\n",
            "Episode Length 35\n",
            "Episode Reward: 64.00\n",
            "Episode Length 64\n",
            "Episode Reward: 34.00\n",
            "Episode Length 34\n",
            "Episode Reward: 40.00\n",
            "Episode Length 40\n",
            "Episode Reward: 42.00\n",
            "Episode Length 42\n",
            "Episode Reward: 45.00\n",
            "Episode Length 45\n",
            "Episode Reward: 43.00\n",
            "Episode Length 43\n",
            "Episode Reward: 55.00\n",
            "Episode Length 55\n",
            "Episode Reward: 45.00\n",
            "Episode Length 45\n",
            "Episode Reward: 52.00\n",
            "Episode Length 52\n",
            "Episode Reward: 43.00\n",
            "Episode Length 43\n",
            "Episode Reward: 62.00\n",
            "Episode Length 62\n",
            "Episode Reward: 63.00\n",
            "Episode Length 63\n",
            "Episode Reward: 40.00\n",
            "Episode Length 40\n",
            "Episode Reward: 33.00\n",
            "Episode Length 33\n",
            "Episode Reward: 39.00\n",
            "Episode Length 39\n",
            "Episode Reward: 53.00\n",
            "Episode Length 53\n",
            "Episode Reward: 62.00\n",
            "Episode Length 62\n",
            "104 Episodes\n",
            "Mean reward: 47.59 +/- 9.52\n",
            "Mean episode length: 47.59 +/- 9.52\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.enjoy --algo a2c --env CartPole-v1 --no-render --n-timesteps 5000 --folder logs/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w5Il2J0VHPLC"
      },
      "source": [
        "#### Tune Hyperparameters\n",
        "\n",
        "We use [Optuna](https://optuna.org/) for optimizing the hyperparameters.\n",
        "\n",
        "Tune the hyperparameters for PPO, using a tpe sampler and median pruner, 2 parallels jobs,\n",
        "with a budget of 1000 trials and a maximum of 50000 steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2sC22eGHTH-",
        "outputId": "2b879187-2ceb-4ca2-cb99-c036c791d1fa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-11-10 15:53:41.380304: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-10 15:53:41.380364: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-10 15:53:41.380403: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-10 15:53:41.388522: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-11-10 15:53:42.492566: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "========== MountainCar-v0 ==========\n",
            "Seed: 1692125702\n",
            "Loading hyperparameters from: /content/rl-baselines3-zoo/hyperparams/ppo.yml\n",
            "Default hyperparameters for environment (ones being tuned will be overridden):\n",
            "OrderedDict([('ent_coef', 0.0),\n",
            "             ('gae_lambda', 0.98),\n",
            "             ('gamma', 0.99),\n",
            "             ('n_envs', 16),\n",
            "             ('n_epochs', 4),\n",
            "             ('n_steps', 16),\n",
            "             ('n_timesteps', 1000000.0),\n",
            "             ('normalize', True),\n",
            "             ('policy', 'MlpPolicy')])\n",
            "Using 16 environments\n",
            "Overwriting n_timesteps with n=50000\n",
            "Doing 1 intermediate evaluations for pruning based on the number of timesteps. (1 evaluation every 100k timesteps)\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Optimizing hyperparameters\n",
            "/usr/local/lib/python3.10/dist-packages/optuna/samplers/_tpe/sampler.py:295: ExperimentalWarning: ``multivariate`` option is an experimental feature. The interface can change in the future.\n",
            "  warnings.warn(\n",
            "Sampler: tpe - Pruner: median\n",
            "\u001b[32m[I 2023-11-10 15:53:45,054]\u001b[0m A new study created in memory with name: no-name-5d158688-f282-4a96-9841-c38f71383425\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 15:58:42,164]\u001b[0m Trial 0 finished with value: -186.4 and parameters: {'batch_size': 32, 'n_steps': 16, 'gamma': 0.95, 'learning_rate': 0.010233214207977993, 'ent_coef': 4.3724685556140656e-07, 'clip_range': 0.2, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.01072139629126112, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 0 with value: -186.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:03:14,629]\u001b[0m Trial 1 finished with value: -138.8 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.999, 'learning_rate': 0.00033641272033588124, 'ent_coef': 1.1842707253003745e-07, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.8644757544385698, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:07:26,694]\u001b[0m Trial 2 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 16, 'gamma': 0.995, 'learning_rate': 0.044008176020508286, 'ent_coef': 0.04531619041049836, 'clip_range': 0.4, 'n_epochs': 20, 'gae_lambda': 0.92, 'max_grad_norm': 5, 'vf_coef': 0.8223199535365006, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:08:37,012]\u001b[0m Trial 4 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 16, 'gamma': 0.95, 'learning_rate': 0.005238675036459905, 'ent_coef': 2.637406807797957e-07, 'clip_range': 0.4, 'n_epochs': 1, 'gae_lambda': 0.8, 'max_grad_norm': 0.5, 'vf_coef': 0.7634706694580814, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:08:41,310]\u001b[0m Trial 3 finished with value: -200.0 and parameters: {'batch_size': 8, 'n_steps': 16, 'gamma': 0.99, 'learning_rate': 1.0274251501140725e-05, 'ent_coef': 8.412073508129362e-08, 'clip_range': 0.4, 'n_epochs': 5, 'gae_lambda': 0.9, 'max_grad_norm': 0.5, 'vf_coef': 0.28734239472605394, 'net_arch': 'medium', 'activation_fn': 'relu'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:09:04,803]\u001b[0m Trial 6 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 256, 'gamma': 0.98, 'learning_rate': 0.014474466795055018, 'ent_coef': 0.00046153885295184164, 'clip_range': 0.2, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 1, 'vf_coef': 0.06319151063681439, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:09:39,031]\u001b[0m Trial 7 finished with value: -200.0 and parameters: {'batch_size': 256, 'n_steps': 1024, 'gamma': 0.9, 'learning_rate': 0.008306675636112192, 'ent_coef': 3.7096809395855235e-05, 'clip_range': 0.4, 'n_epochs': 5, 'gae_lambda': 0.9, 'max_grad_norm': 0.9, 'vf_coef': 0.6059006232949911, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:09:39,340]\u001b[0m Trial 5 finished with value: -200.0 and parameters: {'batch_size': 512, 'n_steps': 1024, 'gamma': 0.995, 'learning_rate': 0.0003481854878209134, 'ent_coef': 0.01576646931111138, 'clip_range': 0.2, 'n_epochs': 20, 'gae_lambda': 0.98, 'max_grad_norm': 0.8, 'vf_coef': 0.18049637340674574, 'net_arch': 'small', 'activation_fn': 'relu'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:11:01,619]\u001b[0m Trial 9 finished with value: -157.6 and parameters: {'batch_size': 64, 'n_steps': 64, 'gamma': 0.9999, 'learning_rate': 0.00011243586657493876, 'ent_coef': 4.949284922914084e-06, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.9, 'max_grad_norm': 5, 'vf_coef': 0.6693223619118785, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:11:26,990]\u001b[0m Trial 8 finished with value: -200.0 and parameters: {'batch_size': 128, 'n_steps': 512, 'gamma': 0.9, 'learning_rate': 0.0003612754924899806, 'ent_coef': 0.07342509006775906, 'clip_range': 0.4, 'n_epochs': 20, 'gae_lambda': 0.92, 'max_grad_norm': 0.5, 'vf_coef': 0.034532102020900846, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:11:52,792]\u001b[0m Trial 10 finished with value: -200.0 and parameters: {'batch_size': 16, 'n_steps': 512, 'gamma': 0.9999, 'learning_rate': 0.06510113711042459, 'ent_coef': 0.014077963227803176, 'clip_range': 0.1, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 0.3, 'vf_coef': 0.5657000318819694, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:16:24,075]\u001b[0m Trial 12 finished with value: -143.2 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.0007344914372835547, 'ent_coef': 1.052653442220059e-08, 'clip_range': 0.3, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.9086133300870867, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:20:54,325]\u001b[0m Trial 11 finished with value: -154.8 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.95, 'learning_rate': 0.00252145196123719, 'ent_coef': 7.4525225946605474e-06, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 5, 'vf_coef': 0.9178862004610889, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:22:17,570]\u001b[0m Trial 14 finished with value: -157.6 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 3.216613522809175e-05, 'ent_coef': 2.410930354360232e-07, 'clip_range': 0.3, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.7769015586493704, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:25:12,106]\u001b[0m Trial 13 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.09986557886259423, 'ent_coef': 1.600105564530689e-06, 'clip_range': 0.4, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.8262389765910505, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 1 with value: -138.8.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:27:11,710]\u001b[0m Trial 15 finished with value: -122.4 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.0009656565186596693, 'ent_coef': 2.0574953189233025e-07, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.6036441109419688, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:29:52,518]\u001b[0m Trial 16 finished with value: -147.6 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.00010214778364294758, 'ent_coef': 1.9437049127992585e-07, 'clip_range': 0.2, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.9370903512325716, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:32:09,888]\u001b[0m Trial 17 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.9999, 'learning_rate': 0.04904990907241964, 'ent_coef': 1.5644525327780072e-06, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.38991464653490693, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:34:06,185]\u001b[0m Trial 19 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 2048, 'gamma': 0.999, 'learning_rate': 0.0001048907872431415, 'ent_coef': 4.183623288458574e-08, 'clip_range': 0.2, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.95770675846911, 'net_arch': 'tiny', 'activation_fn': 'relu'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:34:33,684]\u001b[0m Trial 18 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 16, 'gamma': 0.999, 'learning_rate': 0.023939373574122326, 'ent_coef': 3.214044259596061e-07, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 2, 'vf_coef': 0.8463429021179244, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:35:37,962]\u001b[0m Trial 21 finished with value: -200.0 and parameters: {'batch_size': 64, 'n_steps': 1024, 'gamma': 0.995, 'learning_rate': 0.0026198155460940274, 'ent_coef': 1.6399843634029057e-07, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.99, 'max_grad_norm': 0.7, 'vf_coef': 0.6240071889486551, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:43:35,021]\u001b[0m Trial 20 finished with value: -169.4 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.9, 'learning_rate': 2.5037938603714168e-05, 'ent_coef': 5.510892595534829e-08, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.8, 'max_grad_norm': 0.3, 'vf_coef': 0.9202898285029382, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:44:26,137]\u001b[0m Trial 22 finished with value: -142.4 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.9999, 'learning_rate': 0.00016146291712057837, 'ent_coef': 1.0303728938450036e-06, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.6598538172477665, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:44:53,864]\u001b[0m Trial 23 finished with value: -154.0 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.999, 'learning_rate': 0.00017816215602526535, 'ent_coef': 1.4314324423372285e-07, 'clip_range': 0.3, 'n_epochs': 1, 'gae_lambda': 0.9, 'max_grad_norm': 0.5, 'vf_coef': 0.7085967740520416, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:45:39,671]\u001b[0m Trial 24 finished with value: -183.2 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.9999, 'learning_rate': 2.3971239770106623e-05, 'ent_coef': 1.3661449086882965e-08, 'clip_range': 0.4, 'n_epochs': 1, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.857017310019022, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 15 with value: -122.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:46:30,455]\u001b[0m Trial 25 finished with value: -119.4 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.999, 'learning_rate': 0.00057532946365108, 'ent_coef': 1.382293684213632e-07, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.7327368037154449, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 25 with value: -119.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:51:51,458]\u001b[0m Trial 27 finished with value: -111.6 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.0002671685305315186, 'ent_coef': 3.3651953090421713e-07, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.9, 'max_grad_norm': 0.7, 'vf_coef': 0.5064397856570201, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 27 with value: -111.6.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:55:21,370]\u001b[0m Trial 26 finished with value: -118.0 and parameters: {'batch_size': 128, 'n_steps': 8, 'gamma': 0.999, 'learning_rate': 0.0006718487744019069, 'ent_coef': 3.838934862642277e-08, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.4044093101093273, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 27 with value: -111.6.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:56:03,008]\u001b[0m Trial 29 pruned. \u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 16:57:13,644]\u001b[0m Trial 30 finished with value: -154.0 and parameters: {'batch_size': 128, 'n_steps': 2048, 'gamma': 0.999, 'learning_rate': 0.0030267056540710328, 'ent_coef': 6.147904842649283e-07, 'clip_range': 0.2, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.2601471069466986, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 27 with value: -111.6.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:02:09,030]\u001b[0m Trial 31 finished with value: -118.8 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.002803510872259356, 'ent_coef': 1.0338901197979476e-06, 'clip_range': 0.1, 'n_epochs': 5, 'gae_lambda': 0.9, 'max_grad_norm': 0.7, 'vf_coef': 0.42514938453189444, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 27 with value: -111.6.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:03:33,478]\u001b[0m Trial 32 finished with value: -123.8 and parameters: {'batch_size': 64, 'n_steps': 256, 'gamma': 0.999, 'learning_rate': 6.477696058469317e-05, 'ent_coef': 8.416112440161449e-07, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.8, 'max_grad_norm': 5, 'vf_coef': 0.7098436478576239, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 27 with value: -111.6.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:12:20,508]\u001b[0m Trial 28 finished with value: -111.4 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.00039787361065867757, 'ent_coef': 1.9218542033799028e-08, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 0.9, 'max_grad_norm': 0.8, 'vf_coef': 0.3198143846903466, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 28 with value: -111.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:13:07,009]\u001b[0m Trial 33 pruned. \u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:31:59,615]\u001b[0m Trial 35 finished with value: -113.2 and parameters: {'batch_size': 128, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.00011129344849146392, 'ent_coef': 1.4183211735008917e-07, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 0.9, 'max_grad_norm': 0.8, 'vf_coef': 0.11450889309367243, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 28 with value: -111.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:32:34,057]\u001b[0m Trial 34 pruned. \u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:35:20,531]\u001b[0m Trial 37 pruned. \u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:38:05,255]\u001b[0m Trial 38 pruned. \u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:50:48,084]\u001b[0m Trial 36 finished with value: -140.8 and parameters: {'batch_size': 64, 'n_steps': 8, 'gamma': 0.98, 'learning_rate': 1.5599555356425822e-05, 'ent_coef': 1.0152262015707215e-07, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 1.0, 'max_grad_norm': 0.8, 'vf_coef': 0.20621994257223458, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 28 with value: -111.4.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 17:56:37,090]\u001b[0m Trial 39 finished with value: -111.2 and parameters: {'batch_size': 128, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.00022661152703674323, 'ent_coef': 2.1034635556339908e-07, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 0.9, 'max_grad_norm': 0.8, 'vf_coef': 0.17574108618283152, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 39 with value: -111.2.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:07:43,742]\u001b[0m Trial 40 finished with value: -143.6 and parameters: {'batch_size': 128, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 7.240172430123524e-05, 'ent_coef': 1.1345003432718353e-08, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 0.9, 'max_grad_norm': 0.6, 'vf_coef': 0.3530357926894845, 'net_arch': 'tiny', 'activation_fn': 'tanh'}. Best is trial 39 with value: -111.2.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:08:59,479]\u001b[0m Trial 42 finished with value: -148.6 and parameters: {'batch_size': 128, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 8.077744067057191e-05, 'ent_coef': 5.430672288104226e-07, 'clip_range': 0.1, 'n_epochs': 1, 'gae_lambda': 0.95, 'max_grad_norm': 0.8, 'vf_coef': 0.16137626114606488, 'net_arch': 'medium', 'activation_fn': 'tanh'}. Best is trial 39 with value: -111.2.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:14:58,613]\u001b[0m Trial 41 pruned. \u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:15:56,892]\u001b[0m Trial 44 pruned. \u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:18:29,957]\u001b[0m Trial 43 finished with value: -112.4 and parameters: {'batch_size': 128, 'n_steps': 8, 'gamma': 0.98, 'learning_rate': 0.0003596875558613008, 'ent_coef': 1.1786782235856377e-07, 'clip_range': 0.1, 'n_epochs': 10, 'gae_lambda': 0.9, 'max_grad_norm': 0.8, 'vf_coef': 0.07494322056684169, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 39 with value: -111.2.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:26:08,115]\u001b[0m Trial 45 finished with value: -147.2 and parameters: {'batch_size': 128, 'n_steps': 8, 'gamma': 0.995, 'learning_rate': 0.001798680708241361, 'ent_coef': 1.3050468550228968e-08, 'clip_range': 0.3, 'n_epochs': 10, 'gae_lambda': 0.99, 'max_grad_norm': 0.5, 'vf_coef': 0.30741967441709417, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 39 with value: -111.2.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:27:07,897]\u001b[0m Trial 47 finished with value: -151.2 and parameters: {'batch_size': 128, 'n_steps': 128, 'gamma': 0.98, 'learning_rate': 7.889617511465323e-05, 'ent_coef': 4.833421305645577e-08, 'clip_range': 0.1, 'n_epochs': 10, 'gae_lambda': 0.9, 'max_grad_norm': 0.8, 'vf_coef': 0.15221393704341535, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 39 with value: -111.2.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n",
            "\u001b[32m[I 2023-11-10 18:28:08,846]\u001b[0m Trial 46 finished with value: -112.6 and parameters: {'batch_size': 128, 'n_steps': 16, 'gamma': 0.995, 'learning_rate': 7.394247487285408e-05, 'ent_coef': 1.121475143390904e-08, 'clip_range': 0.1, 'n_epochs': 20, 'gae_lambda': 0.9, 'max_grad_norm': 0.8, 'vf_coef': 0.08731889226805746, 'net_arch': 'small', 'activation_fn': 'tanh'}. Best is trial 39 with value: -111.2.\u001b[0m\n",
            "Normalization activated: {'gamma': 0.99}\n",
            "Normalization activated: {'gamma': 0.99, 'norm_reward': False, 'training': False}\n"
          ]
        }
      ],
      "source": [
        "!python -m rl_zoo3.train --algo ppo --env MountainCar-v0 -n 50000 -optimize --n-trials 1000 --n-jobs 2 --sampler tpe --pruner median"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xVm9QPNVwKXN"
      },
      "source": [
        "### Record  a Video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MPyfQxD5z26J"
      },
      "outputs": [],
      "source": [
        "# Set up display; otherwise rendering will fail\n",
        "import os\n",
        "os.system(\"Xvfb :1 -screen 0 1024x768x24 &\")\n",
        "os.environ['DISPLAY'] = ':1'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ip3AauLzwNGP"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.record_video --algo a2c --env CartPole-v1 --exp-id 0 -f logs/ -n 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBuUfnzI8DN6"
      },
      "source": [
        "### Display the video"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZC3OTfpf8CXu"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "from pathlib import Path\n",
        "\n",
        "from IPython import display as ipythondisplay\n",
        "\n",
        "\n",
        "def show_videos(video_path=\"\", prefix=\"\"):\n",
        "    \"\"\"\n",
        "    Taken from https://github.com/eleurent/highway-env\n",
        "\n",
        "    :param video_path: (str) Path to the folder containing videos\n",
        "    :param prefix: (str) Filter the video, showing only the only starting with this prefix\n",
        "    \"\"\"\n",
        "    html = []\n",
        "    for mp4 in Path(video_path).glob(\"{}*.mp4\".format(prefix)):\n",
        "        video_b64 = base64.b64encode(mp4.read_bytes())\n",
        "        html.append(\n",
        "            \"\"\"<video alt=\"{}\" autoplay\n",
        "                    loop controls style=\"height: 400px;\">\n",
        "                    <source src=\"data:video/mp4;base64,{}\" type=\"video/mp4\" />\n",
        "                </video>\"\"\".format(\n",
        "                mp4, video_b64.decode(\"ascii\")\n",
        "            )\n",
        "        )\n",
        "    ipythondisplay.display(ipythondisplay.HTML(data=\"<br>\".join(html)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oKOjFuwK9HI0"
      },
      "outputs": [],
      "source": [
        "show_videos(video_path='logs/a2c/CartPole-v1_1/videos/', prefix='')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjdpP0HE8D2p"
      },
      "source": [
        "### Continue Training\n",
        "\n",
        "Here, we will continue training of the previous model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zgMZQJJF6u1C"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.train --algo a2c --env CartPole-v1 --n-timesteps 50000 -i logs/a2c/CartPole-v1_1/CartPole-v1.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GSaoyiAE8cVj"
      },
      "outputs": [],
      "source": [
        "!python -m rl_zoo3.enjoy --algo a2c --env CartPole-v1 --no-render --n-timesteps 1000 --folder logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jL9u4I1H-48O"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "rl-baselines-zoo.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "767d51c1340bd893661ea55ea3124f6de3c7a262a8b4abca0554b478b1e2ff90"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}